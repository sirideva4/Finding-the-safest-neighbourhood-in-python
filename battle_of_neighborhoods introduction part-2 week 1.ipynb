{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Data aquisition and Cleaning "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.1 Data Aquisition"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The data aquired for this project is from three sources. The first data source uses a chicago crime that shows all the crimes from 2001 till 2020 in Chicago. The dataset contains the following columns: \n1. ID\n2. Case number\n3. Date\n4. Primary type\n5. Beat\n6. District\n7. Community area\n8. FBI code\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The second source is scraped from a wikipedia page that contains the list of community areas. This page also contains additional information about each community area.\n1. Serial number\n2. Name\n3. Area (sq kms)\n4. 2017 population density (per square km)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The third data source is a list of all the neighborhoods in each community area as found on a wikipedia page. Tha dataset is created from scratch using the data frm the website. The following are the columns:\n1. Neighborhood\n2. Community area\n3. Latitude\n4. Longitude"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<br>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<br>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2.2 Data Cleaning"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The data preparation for each of the three sources was done separately. From the crime in chicago dataset the crimes of year 2017 are only selected.The second data is scraped from a Wikipedia page .We make sure that the community area numbers are same so that we can merge the dataframes using these numbers(1-77) to identify the community area with the least crimes in the year 2017.<br><br><br><br>After visualising the crime in each community area we can find the community with the least crime rate and hence tag the safest community area. <br>The third source of data is created from the list of neighbourhoods from scratch using the list available on Wikipedia. The new dataset is used to generate the venues for each neighbourhood using the Foursquare API.\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}